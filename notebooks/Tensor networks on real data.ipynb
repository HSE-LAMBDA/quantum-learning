{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import tntorch as tn\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, train_X, train_y = lib.read_data('../data/2019_12_29_haar_dim4_0.dat')\n",
    "dim = rho.shape[0]\n",
    "n_qubits = np.log2(dim)\n",
    "\n",
    "tensor_rank = 2**n_qubits\n",
    "batch_size = 100\n",
    "lr = 1e-3\n",
    "\n",
    "sigma = lib.simulator.randomMixedState(rho.shape[0])\n",
    "sigma_real, sigma_imag = [tn.Tensor(x, ranks_tt=tensor_rank, requires_grad=True) for x in [np.real(sigma), np.imag(sigma)]]\n",
    "\n",
    "epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "iter: 0 |  loss: 33.11676025390625 | eval_loss: -0.5860968114111752 | total time: 0.16710543632507324\n",
      "iter: 10 |  loss: 32.244232177734375 | eval_loss: -0.6025110824562516 | total time: 1.5547106266021729\n",
      "iter: 20 |  loss: 28.429380416870117 | eval_loss: -0.6025762969815024 | total time: 2.936919689178467\n",
      "iter: 30 |  loss: 27.644153594970703 | eval_loss: -0.6026209020350124 | total time: 4.3172266483306885\n",
      "iter: 40 |  loss: 28.58127212524414 | eval_loss: -0.6026386650438132 | total time: 5.701262474060059\n",
      "iter: 50 |  loss: 26.781190872192383 | eval_loss: -0.6027080739468862 | total time: 7.084668874740601\n",
      "iter: 60 |  loss: 25.110837936401367 | eval_loss: -0.6027198753265989 | total time: 8.497791528701782\n",
      "iter: 70 |  loss: 31.821475982666016 | eval_loss: -0.6029248329029296 | total time: 9.90051817893982\n",
      "iter: 80 |  loss: 28.520763397216797 | eval_loss: -0.602796369289432 | total time: 11.300904989242554\n",
      "iter: 90 |  loss: 28.9092960357666 | eval_loss: -0.6026334918973892 | total time: 12.749221324920654\n",
      "iter: 100 |  loss: 26.364871978759766 | eval_loss: -0.6022497379430062 | total time: 14.147586107254028\n",
      "iter: 110 |  loss: 32.795257568359375 | eval_loss: -0.6019159052434399 | total time: 15.548684120178223\n",
      "iter: 120 |  loss: 26.9575252532959 | eval_loss: -0.6015310000890088 | total time: 16.95753836631775\n",
      "iter: 130 |  loss: 28.820404052734375 | eval_loss: -0.6009177652605653 | total time: 18.34451699256897\n",
      "iter: 140 |  loss: 31.218523025512695 | eval_loss: -0.600750295749494 | total time: 19.72521471977234\n",
      "iter: 150 |  loss: 29.34274673461914 | eval_loss: -0.6004585160765227 | total time: 21.10789918899536\n",
      "iter: 160 |  loss: 27.6289119720459 | eval_loss: -0.6001867782432087 | total time: 22.48866581916809\n",
      "iter: 170 |  loss: 26.53729248046875 | eval_loss: -0.6000845395207371 | total time: 23.870453119277954\n",
      "iter: 180 |  loss: 29.299280166625977 | eval_loss: -0.5998567316566468 | total time: 25.276737213134766\n",
      "iter: 190 |  loss: 27.770475387573242 | eval_loss: -0.599511332406467 | total time: 26.675440788269043\n",
      "iter: 200 |  loss: 31.22127914428711 | eval_loss: -0.5989832502022282 | total time: 28.07057762145996\n",
      "iter: 210 |  loss: 30.606075286865234 | eval_loss: -0.5984317952726658 | total time: 29.520241022109985\n",
      "iter: 220 |  loss: 26.34535026550293 | eval_loss: -0.5974211168098772 | total time: 30.91257071495056\n",
      "iter: 230 |  loss: 27.7623233795166 | eval_loss: -0.5969175912959319 | total time: 32.313783407211304\n",
      "iter: 240 |  loss: 30.45191192626953 | eval_loss: -0.5962806072884271 | total time: 33.71725940704346\n",
      "iter: 250 |  loss: 29.016000747680664 | eval_loss: -0.5950716288714719 | total time: 35.10323524475098\n",
      "iter: 260 |  loss: 30.444950103759766 | eval_loss: -0.5942296485382791 | total time: 36.48429822921753\n",
      "iter: 270 |  loss: 31.704580307006836 | eval_loss: -0.5933051618573313 | total time: 37.868634939193726\n",
      "iter: 280 |  loss: 29.028732299804688 | eval_loss: -0.5914920548608695 | total time: 39.25248885154724\n",
      "iter: 290 |  loss: 25.377716064453125 | eval_loss: -0.5905539024768793 | total time: 40.64614272117615\n",
      "iter: 300 |  loss: 31.4506778717041 | eval_loss: -0.5895377424091615 | total time: 42.05678844451904\n",
      "iter: 310 |  loss: 26.98016929626465 | eval_loss: -0.5879679638486592 | total time: 43.454479694366455\n",
      "iter: 320 |  loss: 32.4921760559082 | eval_loss: -0.5869907472463737 | total time: 44.89003539085388\n",
      "iter: 330 |  loss: 27.65200424194336 | eval_loss: -0.5860341310961635 | total time: 46.30256199836731\n",
      "iter: 340 |  loss: 28.457489013671875 | eval_loss: -0.5839534824364992 | total time: 47.69043850898743\n",
      "iter: 350 |  loss: 25.618623733520508 | eval_loss: -0.5827467446166493 | total time: 49.09966444969177\n",
      "iter: 360 |  loss: 29.287870407104492 | eval_loss: -0.5815338099142296 | total time: 50.488211154937744\n",
      "iter: 370 |  loss: 27.923871994018555 | eval_loss: -0.57951584832613 | total time: 51.8715124130249\n",
      "iter: 380 |  loss: 28.4963436126709 | eval_loss: -0.5779381911305433 | total time: 53.2567412853241\n",
      "iter: 390 |  loss: 25.68001365661621 | eval_loss: -0.5765068986722997 | total time: 54.639158964157104\n",
      "iter: 400 |  loss: 28.51076316833496 | eval_loss: -0.5740975178482278 | total time: 56.026567220687866\n",
      "iter: 410 |  loss: 26.018672943115234 | eval_loss: -0.5730117386459074 | total time: 57.43288779258728\n",
      "iter: 420 |  loss: 30.0782527923584 | eval_loss: -0.5719005505070036 | total time: 58.833587646484375\n",
      "iter: 430 |  loss: 28.45046615600586 | eval_loss: -0.5698280771061778 | total time: 60.233927488327026\n",
      "iter: 440 |  loss: 29.08039093017578 | eval_loss: -0.5686338143416154 | total time: 61.67646026611328\n",
      "iter: 450 |  loss: 24.887483596801758 | eval_loss: -0.5672097372098884 | total time: 63.0709285736084\n",
      "iter: 460 |  loss: 28.41109275817871 | eval_loss: -0.5650076107690615 | total time: 64.48627424240112\n",
      "iter: 470 |  loss: 28.154600143432617 | eval_loss: -0.5637787041384372 | total time: 65.87829494476318\n",
      "iter: 480 |  loss: 26.57563591003418 | eval_loss: -0.5624750521118959 | total time: 67.26582360267639\n",
      "iter: 490 |  loss: 27.90020179748535 | eval_loss: -0.5601522372185265 | total time: 68.65318822860718\n",
      "iter: 500 |  loss: 27.661977767944336 | eval_loss: -0.5588787116453274 | total time: 70.03551697731018\n",
      "iter: 510 |  loss: 26.79336166381836 | eval_loss: -0.5573978080213216 | total time: 71.41978764533997\n",
      "iter: 520 |  loss: 28.274215698242188 | eval_loss: -0.5547603584786482 | total time: 72.82479166984558\n",
      "iter: 530 |  loss: 30.795991897583008 | eval_loss: -0.5532805769319026 | total time: 74.22018480300903\n",
      "iter: 540 |  loss: 29.339683532714844 | eval_loss: -0.552020922184365 | total time: 75.61861109733582\n",
      "iter: 550 |  loss: 26.948226928710938 | eval_loss: -0.5503702100813883 | total time: 77.05881452560425\n",
      "iter: 560 |  loss: 25.224960327148438 | eval_loss: -0.5489624446167162 | total time: 78.44494700431824\n",
      "iter: 570 |  loss: 28.0850887298584 | eval_loss: -0.5476620293186911 | total time: 79.86207318305969\n",
      "iter: 580 |  loss: 24.557878494262695 | eval_loss: -0.5453696323907543 | total time: 81.25182604789734\n",
      "iter: 590 |  loss: 22.2415714263916 | eval_loss: -0.5445573889232221 | total time: 82.6338381767273\n",
      "iter: 600 |  loss: 28.21592140197754 | eval_loss: -0.5435545839033769 | total time: 84.02086114883423\n",
      "iter: 610 |  loss: 25.41197967529297 | eval_loss: -0.5414665171780798 | total time: 85.39886283874512\n",
      "iter: 620 |  loss: 25.75830841064453 | eval_loss: -0.5401510322243435 | total time: 86.78017449378967\n",
      "iter: 630 |  loss: 24.59080696105957 | eval_loss: -0.5393787867171468 | total time: 88.16509127616882\n",
      "iter: 640 |  loss: 26.07137680053711 | eval_loss: -0.5378093717181995 | total time: 89.56639647483826\n",
      "iter: 650 |  loss: 25.503576278686523 | eval_loss: -0.5367214160075465 | total time: 90.97695970535278\n",
      "iter: 660 |  loss: 24.38789939880371 | eval_loss: -0.535783061117319 | total time: 92.362961769104\n",
      "iter: 670 |  loss: 24.797101974487305 | eval_loss: -0.5342370058098092 | total time: 93.76201272010803\n",
      "iter: 680 |  loss: 28.336618423461914 | eval_loss: -0.5335644737438849 | total time: 95.20943903923035\n",
      "iter: 690 |  loss: 27.151796340942383 | eval_loss: -0.5328084769672282 | total time: 96.6326801776886\n",
      "iter: 700 |  loss: 24.983951568603516 | eval_loss: -0.5316898702593155 | total time: 98.01794123649597\n",
      "iter: 710 |  loss: 27.198026657104492 | eval_loss: -0.5312792505871826 | total time: 99.4099760055542\n",
      "iter: 720 |  loss: 24.806249618530273 | eval_loss: -0.5309864041774583 | total time: 100.82093977928162\n",
      "iter: 730 |  loss: 27.790863037109375 | eval_loss: -0.5303232930556048 | total time: 102.22455382347107\n",
      "iter: 740 |  loss: 24.5645809173584 | eval_loss: -0.5302783073166999 | total time: 103.60389184951782\n",
      "iter: 750 |  loss: 26.482454299926758 | eval_loss: -0.5302351023522699 | total time: 104.9815661907196\n",
      "iter: 760 |  loss: 28.61882209777832 | eval_loss: -0.5299550873625647 | total time: 106.36396789550781\n",
      "iter: 770 |  loss: 28.860897064208984 | eval_loss: -0.5301607101831782 | total time: 107.74617743492126\n",
      "iter: 780 |  loss: 26.901975631713867 | eval_loss: -0.5303727926109447 | total time: 109.12714099884033\n",
      "iter: 790 |  loss: 23.58623695373535 | eval_loss: -0.5305976592404225 | total time: 110.50647616386414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 800 |  loss: 26.378082275390625 | eval_loss: -0.5306861481709461 | total time: 111.89225745201111\n",
      "iter: 810 |  loss: 25.092790603637695 | eval_loss: -0.530704846524837 | total time: 113.3053936958313\n",
      "iter: 820 |  loss: 25.703317642211914 | eval_loss: -0.5310325215157987 | total time: 114.70702075958252\n",
      "iter: 830 |  loss: 26.389122009277344 | eval_loss: -0.5315268546626659 | total time: 116.08695268630981\n",
      "iter: 840 |  loss: 24.25170135498047 | eval_loss: -0.5317761634913366 | total time: 117.51441144943237\n",
      "iter: 850 |  loss: 22.186155319213867 | eval_loss: -0.5319385589335645 | total time: 118.95687198638916\n",
      "iter: 860 |  loss: 23.096206665039062 | eval_loss: -0.5322230917818243 | total time: 120.34032773971558\n",
      "iter: 870 |  loss: 22.78999137878418 | eval_loss: -0.5323123204841729 | total time: 121.73070907592773\n",
      "iter: 880 |  loss: 23.137069702148438 | eval_loss: -0.5327695109840619 | total time: 123.13912606239319\n",
      "iter: 890 |  loss: 27.09807777404785 | eval_loss: -0.5329687226865858 | total time: 124.53956198692322\n",
      "iter: 900 |  loss: 21.87135887145996 | eval_loss: -0.533274113454989 | total time: 125.92200827598572\n",
      "iter: 910 |  loss: 27.367517471313477 | eval_loss: -0.5340649792182888 | total time: 127.29849910736084\n",
      "iter: 920 |  loss: 24.542943954467773 | eval_loss: -0.5341733252736229 | total time: 128.67560291290283\n",
      "iter: 930 |  loss: 23.305158615112305 | eval_loss: -0.5344111529191635 | total time: 130.05470085144043\n",
      "iter: 940 |  loss: 25.703920364379883 | eval_loss: -0.5349070270936163 | total time: 131.43496751785278\n",
      "iter: 950 |  loss: 28.08560562133789 | eval_loss: -0.5350893446987943 | total time: 132.8145923614502\n",
      "iter: 960 |  loss: 25.303224563598633 | eval_loss: -0.5356777643426569 | total time: 134.19599533081055\n",
      "iter: 970 |  loss: 28.016138076782227 | eval_loss: -0.5363651447161001 | total time: 135.59562182426453\n",
      "iter: 980 |  loss: 24.093599319458008 | eval_loss: -0.5366720136348195 | total time: 137.00416350364685\n",
      "iter: 990 |  loss: 22.997411727905273 | eval_loss: -0.5375791871060582 | total time: 138.39010500907898\n",
      "iter: 1000 |  loss: 27.342191696166992 | eval_loss: -0.5390469410801524 | total time: 139.7943778038025\n",
      "iter: 1007 |  loss: 26.7205753326416 | eval_loss: -0.5394788783074645 | total time: 140.8050594329834\n",
      " <- converged (Eval loss stopped increasing)\n"
     ]
    }
   ],
   "source": [
    "def trace(tensor):\n",
    "    if len(tensor.shape) == 2:\n",
    "        return sum([tensor[i,i] for i in range(tensor.shape[0])])\n",
    "    if len(tensor.shape) == 3:\n",
    "        return sum([tensor[:, i,i] for i in range(tensor.shape[1])])\n",
    "\n",
    "def cholesky(sigma_real, sigma_imag):\n",
    "    sigma_real, sigma_imag = sigma_real.dot(sigma_real, k=1)+sigma_imag.dot(sigma_imag, k=1), sigma_real.dot(sigma_imag, k=1)-sigma_imag.dot(sigma_real, k=1)\n",
    "    trace = sum([sigma_real[i,i] for i in range(rho.shape[0])])\n",
    "    sigma_real, sigma_imag = [x/trace for x in [sigma_real, sigma_imag]]\n",
    "    return sigma_real, sigma_imag\n",
    "    \n",
    "#initial_trace = sum((np.real(trace(test_X.dot(sigma)))-test_y)**2)\n",
    "\n",
    "def loss(sigma_real, sigma_imag):\n",
    "    sigma_real, sigma_imag = cholesky(sigma_real, sigma_imag)\n",
    "    res = 0\n",
    "    idx = np.random.choice(np.arange(train_X.shape[0]), batch_size)\n",
    "    for E_m,y_m in zip(train_X[idx], train_y[idx].astype('float64')):\n",
    "        E_real, E_imag = [tn.Tensor(x) for x in [np.real(E_m), np.imag(E_m)]]\n",
    "        res += ((E_real.dot(sigma_real)+E_imag.dot(sigma_imag)-y_m)**2)\n",
    "#     return res/(initial_trace*train_X.shape[0])\n",
    "    return res\n",
    "    \n",
    "\n",
    "def eval_loss(sigma_real, sigma_imag): # any score function can be used here\n",
    "    sigma_real_, sigma_imag_ = cholesky(sigma_real, sigma_imag)\n",
    "    sigma = sigma_real_.torch().detach().cpu().numpy() + 1j*sigma_imag_.torch().detach().cpu().numpy()\n",
    "    return -lib.fidelity(sigma, rho)\n",
    "\n",
    "#print('Trace before: %f'%initial_trace)\n",
    "\n",
    "lib.tn_optimize([sigma_real, sigma_imag], loss, eval_loss, tol=0, patience=1000,print_freq=10,lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396036625798617"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_real_, sigma_imag_ = cholesky(sigma_real, sigma_imag)\n",
    "sigma = sigma_real_.torch().detach().cpu().numpy() + 1j*sigma_imag_.torch().detach().cpu().numpy()\n",
    "sigma /= sum([sigma[i,i] for i in range(int(2**n_qubits))])\n",
    "lib.fidelity(sigma, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
