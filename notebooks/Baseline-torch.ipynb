{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "В рамках данной задачи предстоит научиться получать наилучшее приближение $\\sigma\\in\\mathbb{C}^n$ истинного квантового состояния $\\rho\\in\\mathbb{C}^n$ по некоторой обучающей выборке $X_{train}=\\{E_m,y_m\\}_{m=0}^{N}$, где $E_m$ - некоторая матрица (называемая оператор, проектор), $y_m$ - некоторое наблюдение (проекция истинного состояния $\\rho$ на этот оператор). \n",
    "\n",
    "В качестве оптимизируемого функционала предлагается минимизировать следующую функцию:\n",
    "$$min_\\sigma[f(\\sigma)=\\Sigma_m(Tr(E_m\\sigma)-Tr(E_m\\rho))^2=\\Sigma_m(Tr(E_m\\sigma)-y_m)^2]$$\n",
    "$$\\sigma\\geq0,Tr(\\sigma)=1$$\n",
    "гдe $\\sigma\\geq0$ означает положительную полуопределённость обучаемой матрицы $\\sigma$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение\n",
    "\n",
    "Поскольку матрица $\\sigma$ - положительно полуопределённая, сделаем разложение Холецкого: $\\sigma=M^*M$. \n",
    "\n",
    "Тогда \n",
    "$$Tr(\\sigma)=Tr(M^*M)=\\Sigma_{a_m\\in M} a_m^*a_m=\\Sigma_{a_m\\in M} |a_m|^2$$\n",
    "\n",
    "Поскольку для любой положительно полуопределённой матрицы существует разложение Холецкого, и, наоборот, для любой матрицы $M\\in\\mathbb{C}^n$ матрица $M^*M$ является положительно полуопределённой, мы можем переписать оптимизационную задачу в виде\n",
    "\n",
    "$$min_M[f(M)=\\Sigma_m(Tr(E_mM^*M)-y_m)^2]$$\n",
    "$$Tr(M^*M)=\\Sigma_{a_m\\in M}|a_m|^2=1$$\n",
    "\n",
    "Эту задачу можно было бы решать обычным методом множителей Лагранжа, но можно просто перенормировать $M$ на $\\sqrt{Tr(M^*M)}$. Тогда задача сведётся к задаче безусловной оптимизации\n",
    "\n",
    "$$min_M[f(M)=\\Sigma_m(Tr(E_m\\frac{M^*M}{Tr(M^*M)})-y_m)^2=\\Sigma_m(Tr(E_m\\frac{M^*M}{\\Sigma_{a_m\\in M}|a_m|^2})-y_m)^2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = np.array([[1., 0.], [0., 0.]]) # target state\n",
    "dim = rho.shape[0]\n",
    "\n",
    "projectors_cnt = 10\n",
    "measurements_cnt = 100\n",
    "\n",
    "train_size = projectors_cnt * measurements_cnt\n",
    "train_X, train_y = lib.generate_dataset(rho, projectors_cnt, measurements_cnt)\n",
    "train_y = train_y.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = lib.ComplexTensor(lib.simulator.randomMixedState(rho.shape[0]))\n",
    "M.requires_grad = True\n",
    "opt = torch.optim.SGD([M], lr=1e-1)\n",
    "epoches = 10\n",
    "\n",
    "def trace(tensor):\n",
    "    return sum([tensor[i:i+1,i:i+1] for i in range(tensor.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.0005043209530413151\n",
      "Epoch: 1, Loss: 0.0005034722271375358\n",
      "Epoch: 2, Loss: 0.000502625189255923\n",
      "Epoch: 3, Loss: 0.0005017802468501031\n",
      "Epoch: 4, Loss: 0.0005009371670894325\n",
      "Epoch: 5, Loss: 0.000500095949973911\n",
      "Epoch: 6, Loss: 0.0004992565955035388\n",
      "Epoch: 7, Loss: 0.0004984191618859768\n",
      "Epoch: 8, Loss: 0.0004975837655365467\n",
      "Epoch: 9, Loss: 0.0004967502900399268\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoches):\n",
    "    sigma = M.t(conjugate=True).mm(M)\n",
    "    norm = trace(sigma).real.sum()\n",
    "\n",
    "    loss = 0\n",
    "    for E_m,y_m in zip(train_X, train_y.astype('float64')):\n",
    "        E_m = lib.ComplexTensor(E_m)\n",
    "        loss += ((trace(E_m.mm(sigma)/norm)-y_m)**2).sum()\n",
    "    loss /= train_size\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.detach().cpu().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6505789 +0.j        , 0.10895082-0.25391927j],\n",
       "       [0.10895082+0.25391927j, 0.3494211 +0.j        ]], dtype=complex64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = sigma/norm\n",
    "sigma = sigma.detach().numpy()[:dim] + 1j*sigma.detach().numpy()[dim:]\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6505789160728455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib.fidelity(rho, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
