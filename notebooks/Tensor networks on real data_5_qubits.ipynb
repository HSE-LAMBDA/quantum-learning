{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import tntorch as tn\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, train_X, train_y = lib.read_data('../data/2020_01_29_stabilizer_dim32_0.dat')\n",
    "dim = rho.shape[0]\n",
    "n_qubits = np.log2(dim)\n",
    "\n",
    "tensor_rank = 2**n_qubits\n",
    "batch_size = 100\n",
    "lr = 1e-3\n",
    "\n",
    "sigma = lib.simulator.randomMixedState(rho.shape[0])\n",
    "sigma_real, sigma_imag = [tn.Tensor(x, ranks_tt=tensor_rank, requires_grad=True) for x in [np.real(sigma), np.imag(sigma)]]\n",
    "\n",
    "epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "iter: 0 |  loss: 53.23578643798828 | eval_loss: -0.04496200178681223 | total time: 0.2689054012298584\n",
      "iter: 10 |  loss: 52.315093994140625 | eval_loss: -0.04493150956139027 | total time: 3.5881080627441406\n",
      "iter: 20 |  loss: 52.11803436279297 | eval_loss: -0.04458478097192715 | total time: 7.150235176086426\n",
      "iter: 30 |  loss: 51.34756851196289 | eval_loss: -0.04394072379661496 | total time: 10.091796398162842\n",
      "iter: 40 |  loss: 53.029273986816406 | eval_loss: -0.042155049215325334 | total time: 13.357889413833618\n",
      "iter: 50 |  loss: 44.427574157714844 | eval_loss: -0.04092186272900992 | total time: 17.000505447387695\n",
      "iter: 60 |  loss: 53.47964096069336 | eval_loss: -0.03983913484005695 | total time: 20.562462329864502\n",
      "iter: 70 |  loss: 51.585205078125 | eval_loss: -0.037769683876909654 | total time: 23.90771174430847\n",
      "iter: 80 |  loss: 50.76714324951172 | eval_loss: -0.03666214583012489 | total time: 26.97423553466797\n",
      "iter: 90 |  loss: 46.91426467895508 | eval_loss: -0.035863951015234895 | total time: 30.152804613113403\n",
      "iter: 100 |  loss: 49.491451263427734 | eval_loss: -0.0343993819225808 | total time: 33.48694372177124\n",
      "iter: 110 |  loss: 47.2401237487793 | eval_loss: -0.03350518691621434 | total time: 36.73050308227539\n",
      "iter: 120 |  loss: 44.035892486572266 | eval_loss: -0.03264898381907982 | total time: 39.90279579162598\n",
      "iter: 130 |  loss: 45.62717056274414 | eval_loss: -0.03130807152445357 | total time: 43.067893743515015\n",
      "iter: 140 |  loss: 47.48978805541992 | eval_loss: -0.030360189542244256 | total time: 46.351582050323486\n",
      "iter: 150 |  loss: 44.49112319946289 | eval_loss: -0.029433060915043 | total time: 49.761528730392456\n",
      "iter: 160 |  loss: 49.61114501953125 | eval_loss: -0.02805653573033257 | total time: 52.73548746109009\n",
      "iter: 170 |  loss: 49.35055160522461 | eval_loss: -0.027354915809806195 | total time: 55.981043577194214\n",
      "iter: 180 |  loss: 47.09377670288086 | eval_loss: -0.026681499219383245 | total time: 59.24773550033569\n",
      "iter: 190 |  loss: 54.863563537597656 | eval_loss: -0.02561740022575505 | total time: 62.78301239013672\n",
      "iter: 200 |  loss: 47.78141784667969 | eval_loss: -0.024903325339707037 | total time: 65.94612121582031\n",
      "iter: 210 |  loss: 46.45695114135742 | eval_loss: -0.024205278931509814 | total time: 69.10642051696777\n",
      "iter: 220 |  loss: 44.65907287597656 | eval_loss: -0.022825118536785618 | total time: 72.50249814987183\n",
      "iter: 230 |  loss: 53.460723876953125 | eval_loss: -0.022057571416058845 | total time: 76.05581736564636\n",
      "iter: 240 |  loss: 52.6891975402832 | eval_loss: -0.021314166145424845 | total time: 79.62875413894653\n",
      "iter: 250 |  loss: 53.33720779418945 | eval_loss: -0.020048617211984508 | total time: 82.97626876831055\n",
      "iter: 260 |  loss: 50.87269973754883 | eval_loss: -0.0192917960495689 | total time: 85.96425199508667\n",
      "iter: 270 |  loss: 52.78580856323242 | eval_loss: -0.018571623725175734 | total time: 90.20814251899719\n",
      "iter: 280 |  loss: 48.491249084472656 | eval_loss: -0.017247495331470297 | total time: 93.6326642036438\n",
      "iter: 290 |  loss: 56.373138427734375 | eval_loss: -0.016469422228294183 | total time: 97.66622996330261\n",
      "iter: 300 |  loss: 49.69675827026367 | eval_loss: -0.015679194436698726 | total time: 101.06765103340149\n",
      "iter: 305 |  loss: 52.68562316894531 | eval_loss: -0.014911489068299321 | total time: 102.60620594024658\n",
      " <- converged (Eval loss stopped increasing)\n"
     ]
    }
   ],
   "source": [
    "def trace(tensor):\n",
    "    if len(tensor.shape) == 2:\n",
    "        return sum([tensor[i,i] for i in range(tensor.shape[0])])\n",
    "    if len(tensor.shape) == 3:\n",
    "        return sum([tensor[:, i,i] for i in range(tensor.shape[1])])\n",
    "\n",
    "def cholesky(sigma_real, sigma_imag):\n",
    "    sigma_real, sigma_imag = sigma_real.dot(sigma_real, k=1)+sigma_imag.dot(sigma_imag, k=1), sigma_real.dot(sigma_imag, k=1)-sigma_imag.dot(sigma_real, k=1)\n",
    "    trace = sum([sigma_real[i,i] for i in range(rho.shape[0])])\n",
    "    sigma_real, sigma_imag = [x/trace for x in [sigma_real, sigma_imag]]\n",
    "    return sigma_real, sigma_imag\n",
    "    \n",
    "#initial_trace = sum((np.real(trace(test_X.dot(sigma)))-test_y)**2)\n",
    "\n",
    "def loss(sigma_real, sigma_imag):\n",
    "    sigma_real, sigma_imag = cholesky(sigma_real, sigma_imag)\n",
    "    res = 0\n",
    "    idx = np.random.choice(np.arange(train_X.shape[0]), batch_size)\n",
    "    for E_m,y_m in zip(train_X[idx], train_y[idx].astype('float64')):\n",
    "        E_real, E_imag = [tn.Tensor(x) for x in [np.real(E_m), np.imag(E_m)]]\n",
    "        res += ((E_real.dot(sigma_real)+E_imag.dot(sigma_imag)-y_m)**2)\n",
    "#     return res/(initial_trace*train_X.shape[0])\n",
    "    return res\n",
    "    \n",
    "\n",
    "def eval_loss(sigma_real, sigma_imag): # any score function can be used here\n",
    "    sigma_real_, sigma_imag_ = cholesky(sigma_real, sigma_imag)\n",
    "    sigma = sigma_real_.torch().detach().cpu().numpy() + 1j*sigma_imag_.torch().detach().cpu().numpy()\n",
    "    return -lib.fidelity(sigma, rho)\n",
    "\n",
    "#print('Trace before: %f'%initial_trace)\n",
    "\n",
    "lib.tn_optimize([sigma_real, sigma_imag], loss, eval_loss, tol=0, patience=300,print_freq=10,lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
