{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "В рамках данной задачи предстоит научиться получать наилучшее приближение $\\sigma\\in\\mathbb{C}^n$ истинного квантового состояния $\\rho\\in\\mathbb{C}^n$ по некоторой обучающей выборке $X_{train}=\\{E_m,y_m\\}_{m=0}^{N}$, где $E_m$ - некоторая матрица (называемая оператор, проектор), $y_m$ - некоторое наблюдение (проекция истинного состояния $\\rho$ на этот оператор). \n",
    "\n",
    "В качестве оптимизируемого функционала предлагается минимизировать следующую функцию:\n",
    "$$min_\\sigma[f(\\sigma)=\\Sigma_m(Tr(E_m\\sigma)-Tr(E_m\\rho))^2=\\Sigma_m(Tr(E_m\\sigma)-y_m)^2]$$\n",
    "$$\\sigma\\geq0,Tr(\\sigma)=1$$\n",
    "гдe $\\sigma\\geq0$ означает положительную полуопределённость обучаемой матрицы $\\sigma$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение\n",
    "\n",
    "Поскольку матрица $\\sigma$ - положительно полуопределённая, сделаем разложение Холецкого: $\\sigma=M^*M$. \n",
    "\n",
    "Тогда \n",
    "$$Tr(\\sigma)=Tr(M^*M)=\\Sigma_{a_m\\in M} a_m^*a_m=\\Sigma_{a_m\\in M} |a_m|^2$$\n",
    "\n",
    "Поскольку для любой положительно полуопределённой матрицы существует разложение Холецкого, и, наоборот, для любой матрицы $M\\in\\mathbb{C}^n$ матрица $M^*M$ является положительно полуопределённой, мы можем переписать оптимизационную задачу в виде\n",
    "\n",
    "$$min_M[f(M)=\\Sigma_m(Tr(E_mM^*M)-y_m)^2]$$\n",
    "$$Tr(M^*M)=\\Sigma_{a_m\\in M}|a_m|^2=1$$\n",
    "\n",
    "Эту задачу можно было бы решать обычным методом множителей Лагранжа, но можно просто перенормировать $M$ на $\\sqrt{Tr(M^*M)}$. Тогда задача сведётся к задаче безусловной оптимизации\n",
    "\n",
    "$$min_M[f(M)=\\Sigma_m(Tr(E_m\\frac{M^*M}{Tr(M^*M)})-y_m)^2=\\Sigma_m(Tr(E_m\\frac{M^*M}{\\Sigma_{a_m\\in M}|a_m|^2})-y_m)^2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import simulator\n",
    "rho = np.array([[1., 0.], [0., 0.]]) # target state\n",
    "dim = rho.shape[0]\n",
    "projectors_cnt = 10\n",
    "measurements_cnt = 100\n",
    "train_size = projectors_cnt * measurements_cnt\n",
    "train_X, train_y = simulator.generate_dataset(rho, projectors_cnt, measurements_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('pytorch-complex-tensor/')\n",
    "from pytorch_complex_tensor import ComplexTensor\n",
    "M = ComplexTensor(simulator.randomMixedState(rho.shape[0]))\n",
    "M.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "opt = SGD([M], lr=1e-1)\n",
    "epoches = 1000\n",
    "def trace(tensor):\n",
    "    return sum([tensor[i:i+1,i:i+1] for i in range(tensor.shape[0])])\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    sigma = M.t(conjugate=True).mm(M)\n",
    "    norm = trace(sigma).real.sum()\n",
    "\n",
    "    loss = 0\n",
    "    for E_m,y_m in zip(train_X, train_y.astype('float64')):\n",
    "        E_m = ComplexTensor(E_m)\n",
    "        loss += ((trace(E_m.mm(sigma)/norm)-y_m)**2).sum()\n",
    "    loss /= train_size\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.detach().cpu().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9615571 +0.j        , 0.11540203-0.15377726j],\n",
       "       [0.11540203+0.15377726j, 0.03844294+0.j        ]], dtype=complex64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = sigma/norm\n",
    "sigma = sigma.detach().numpy()[:dim] + 1j*sigma.detach().numpy()[dim:]\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.isDensityMatrix(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
