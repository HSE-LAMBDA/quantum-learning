{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "В рамках данной задачи предстоит научиться получать наилучшее приближение $\\sigma\\in\\mathbb{C}^n$ истинного квантового состояния $\\rho\\in\\mathbb{C}^n$ по некоторой обучающей выборке $X_{train}=\\{E_m,y_m\\}_{m=0}^{N}$, где $E_m$ - некоторая матрица (называемая оператор, проектор), $y_m$ - некоторое наблюдение (проекция истинного состояния $\\rho$ на этот оператор). \n",
    "\n",
    "В качестве оптимизируемого функционала предлагается минимизировать следующую функцию:\n",
    "$$min_\\sigma[f(\\sigma)=\\Sigma_m(Tr(E_m\\sigma)-Tr(E_m\\rho))^2=\\Sigma_m(Tr(E_m\\sigma)-y_m)^2]$$\n",
    "$$\\sigma\\geq0,Tr(\\sigma)=1$$\n",
    "гдe $\\sigma\\geq0$ означает положительную полуопределённость обучаемой матрицы $\\sigma$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение\n",
    "Поскольку матрица $\\sigma$ - положительно полуопределённая, сделаем разложение Холецкого: $\\sigma=M^*M$. \n",
    "\n",
    "Тогда \n",
    "$$Tr(\\sigma)=Tr(M^*M)=\\Sigma_{a_m\\in M} a_m^*a_m=\\Sigma_{a_m\\in M} |a_m|^2$$\n",
    "\n",
    "Поскольку для любой положительно полуопределённой матрицы существует разложение Холецкого, и, наоборот, для любой матрицы $M\\in\\mathbb{C}^n$ матрица $M^*M$ является положительно полуопределённой, мы можем переписать оптимизационную задачу в виде\n",
    "\n",
    "$$min_M[f(M)=\\Sigma_m(Tr(E_mM^*M)-y_m)^2]$$\n",
    "$$Tr(M^*M)=\\Sigma_{a_m\\in M}|a_m|^2=1$$\n",
    "\n",
    "Эту задачу можно было бы решать обычным методом множителей Лагранжа, но можно просто перенормировать $M$ на $\\sqrt{Tr(M^*M)}$. Тогда задача сведётся к задаче безусловной оптимизации\n",
    "\n",
    "$$min_M[f(M)=\\Sigma_m(Tr(E_m\\frac{M^*M}{Tr(M^*M)})-y_m)^2=\\Sigma_m(Tr(E_m\\frac{M^*M}{\\Sigma_{a_m\\in M}|a_m|^2})-y_m)^2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import simulator\n",
    "rho = np.array([[1., 0.], [0., 0.]]) # target state\n",
    "dim = rho.shape[0]\n",
    "train_size = 2\n",
    "train_X, train_y = simulator.generate_dataset(rho, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('pytorch-complex-tensor/')\n",
    "from pytorch_complex_tensor import ComplexTensor\n",
    "M = ComplexTensor(simulator.randomMixedState(rho.shape[0]))\n",
    "M.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.6041244268417358\n",
      "Epoch: 1, Loss: 1.6036443710327148\n",
      "Epoch: 2, Loss: 1.6032569408416748\n",
      "Epoch: 3, Loss: 1.6029387712478638\n",
      "Epoch: 4, Loss: 1.6026734113693237\n",
      "Epoch: 5, Loss: 1.602449893951416\n",
      "Epoch: 6, Loss: 1.6022610664367676\n",
      "Epoch: 7, Loss: 1.6020973920822144\n",
      "Epoch: 8, Loss: 1.6019563674926758\n",
      "Epoch: 9, Loss: 1.601832628250122\n",
      "Epoch: 10, Loss: 1.6017251014709473\n",
      "Epoch: 11, Loss: 1.6016281843185425\n",
      "Epoch: 12, Loss: 1.6015437841415405\n",
      "Epoch: 13, Loss: 1.6014670133590698\n",
      "Epoch: 14, Loss: 1.6013984680175781\n",
      "Epoch: 15, Loss: 1.6013376712799072\n",
      "Epoch: 16, Loss: 1.601282000541687\n",
      "Epoch: 17, Loss: 1.6012306213378906\n",
      "Epoch: 18, Loss: 1.6011852025985718\n",
      "Epoch: 19, Loss: 1.6011428833007812\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "opt = SGD([M], lr=1e-1)\n",
    "epoches = 20\n",
    "def trace(tensor):\n",
    "    return sum([tensor[i:i+1,i:i+1] for i in range(tensor.shape[0])])\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    sigma = M.t(conjugate=True).mm(M)\n",
    "    norm = trace(sigma).real.sum()\n",
    "\n",
    "    loss = 0\n",
    "    for E_m,y_m in zip(train_X, train_y.astype('float64')):\n",
    "        E_m = ComplexTensor(E_m)\n",
    "        loss += ((trace(E_m.mm(sigma)/norm)-y_m)**2).sum()\n",
    "    loss /= train_size\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.detach().cpu().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91788   +0.j        , 0.16271587+0.22112666j],\n",
       "       [0.16271587-0.22112666j, 0.08211999+0.j        ]], dtype=complex64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = sigma/norm\n",
    "sigma = sigma.detach().numpy()[:dim] + 1j*sigma.detach().numpy()[dim:]\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.isDensityMatrix(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
